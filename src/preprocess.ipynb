{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7b6b76-13cf-4e3e-83a8-fb1757c4ec23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessor\n",
    "In data science parlance, this notebook performs the Extract, Transform, and Load portion of our workflow. If there is ever a change to our raw data format, we will only ever have to make changes here, or possibly create a fork of this file to support different raw data formats.\n",
    "\n",
    "Extract, Transform, and Load is often shortened to ETL. In our ETL workflow, we will:\n",
    "* Extract the data from the raw csv.\n",
    "* Transform the data into a workable format by converting to SI units\n",
    "* Transform the data by splitting the rolls into multiple datasets.\n",
    "* Load the data into a standard format for our analysis notebooks to consume.\n",
    "\n",
    "### Organization\n",
    "Data is always read from `data/raw` and written out to `data/parsed`. \n",
    "\n",
    "It is important to always preserve the raw data so you can reprocess it if necessary. Your data is very valuable, and disk space is cheap! You never know what changes you or someone else might want to make to the analysis code in the future, and there could be bugs in the code that require reprocessing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37dab6-3c20-4529-8fca-e347e3f3bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from ipywidgets import *\n",
    "from pyproj import Proj\n",
    "\n",
    "from constants import *\n",
    "from plot_utils import *\n",
    "MPH_TO_MPS = 0.44704 # convert miles / hour to meters / second\n",
    "CHUTE_THRESHOLD = START_OF_BACK_HILLS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c45e8-4857-4371-9116-861609bfa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all of the raw data files we will process\n",
    "from glob import glob\n",
    "file_patterns = [\n",
    "    f'{DATA_DIR}/raw/yyyy-mm-dd_*.csv',\n",
    "]\n",
    "raw_files = [file for pattern in file_patterns for file in glob(pattern)]\n",
    "print(f'Found {len(raw_files)} raw data files:')\n",
    "for file in raw_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55207a69-0372-4b62-aec4-79e1e30ab872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each file and convert data to SI units\n",
    "# Plot each file in its own figure to sanity check the data\n",
    "%matplotlib widget\n",
    "data = {}\n",
    "\n",
    "pittsburgh = 17\n",
    "utm_converter = Proj(proj='utm', zone=pittsburgh, ellps='WGS84', preserve_units=False)\n",
    "\n",
    "for raw_file in raw_files:\n",
    "    label = os.path.splitext(os.path.basename(raw_file))[0]\n",
    "    raw = pd.read_csv(raw_file)\n",
    "    df = pd.DataFrame()\n",
    "    data[label] = df\n",
    "    \n",
    "    # convert data to SI units \n",
    "    df[T] = raw['timestamp']\n",
    "    x, y = utm_converter(raw['longitude'], raw['latitude'])\n",
    "    df[X] = x\n",
    "    df[Y] = y\n",
    "    # Z = altitude is already in meters\n",
    "    df[Z] = raw['altitude']\n",
    "    df[SPEED] = raw['ground_speed'] * MPH_TO_MPS\n",
    "    df[STD_X] = raw['horizontal_accuracy'] # already in meters\n",
    "    df[STD_Y] = raw['horizontal_accuracy'] # already in meters\n",
    "    df[STD_Z] = raw['vertical_accuracy'] # already in meters\n",
    "    df[STD_SPEED] = raw['speed_accuracy'] * MPH_TO_MPS\n",
    "    df[FIX_TYPE] = raw['rtktype']\n",
    "    \n",
    "    t = df[T].to_numpy()\n",
    "    s = df[SPEED].to_numpy()\n",
    "    \n",
    "    fig, (birds_eye, speed) = plt.subplots(nrows=2)\n",
    "    fig.suptitle(label)\n",
    "    add_birds_eye_view(birds_eye, x, y, df[T])\n",
    "    birds_eye.axvline(x=CHUTE_THRESHOLD,ls='--', color='gray', lw=0.8)\n",
    "    speed.plot(t,s)\n",
    "    add_crosshairs(speed)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2421c6-ae52-480d-aa59-2a68c2caac27",
   "metadata": {},
   "source": [
    "# Split the data into individual rolls\n",
    "Rolls are counted by the number of times a buggy completes the chute turn. Conveniently, the chute is the westernmost point on the buggy course, so it is easy to detect by looking for points west of CHUTE_THRESHOLD. \n",
    "\n",
    "Knowing 1 data point in the chute, we step through time until a moving average of the buggy's speed is below the threshold to be considered stopped. This identifies the approximate start and end of the roll.\n",
    "\n",
    "Don't worry too much about exactly where the finish line is, or exactly when the buggy starts moving. If you are having trouble finding suitable values for STOPPED_THRESHOLD and DECAY, consider stepping until X is less than some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590434b-0660-4937-a597-9305c1d6c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = defaultdict(list)\n",
    "\n",
    "STOPPED_THRESHOLD = 1 # m/s\n",
    "DECAY = 0.9 # values closer to 1.0 will take a wider average\n",
    "\n",
    "for label in data:\n",
    "    df = data[label]\n",
    "    count = len(df)\n",
    "    mask = [True] * count\n",
    "    \n",
    "    def step_until_stopped(idx, step):\n",
    "        avg_speed = df[SPEED][idx]\n",
    "        while avg_speed > STOPPED_THRESHOLD and 0 <= idx+step < count:\n",
    "            idx += step\n",
    "            avg_speed = DECAY * avg_speed + (1.0 - DECAY) * df[SPEED][idx]\n",
    "        return idx\n",
    "    \n",
    "    while(df[X][mask].min() < CHUTE_THRESHOLD):\n",
    "        idx = df[X][mask].idxmin()\n",
    "        start = step_until_stopped(idx, -1)\n",
    "        end = step_until_stopped(idx, 1)\n",
    "        rolls[label].append((start, end))\n",
    "        mask[start:end] = [False] * (end-start)\n",
    "    \n",
    "    rolls[label].sort()\n",
    "    print(f'{label} => {len(rolls[label])} rolls')\n",
    "    for idx in range(len(rolls[label])):\n",
    "        start, end = rolls[label][idx]\n",
    "        print(f'Roll {idx} start={start}, end={end}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabf715-1b79-4f99-974a-4d61cc86a347",
   "metadata": {},
   "source": [
    "# Sanity Check\n",
    "Before we save the roll data to the output folder, look over each roll and check that it makes sense.\n",
    "\n",
    "At this point, the roll data is just a start/end index into the raw dataframe. If there is an artifact you don't like, consider retuning STOPPED_THRESHOLD and DECAY to fix it programatically, but don't be afraid to create a scratch cell and manually edit the start/end index as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a71e40-e052-4aad-98a2-14f737b3e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for label in rolls:\n",
    "    for idx, (start, end) in enumerate(rolls[label]):\n",
    "        df = data[label]\n",
    "        \n",
    "        fig, (birds_eye, speed) = plt.subplots(nrows=2)\n",
    "        fig.suptitle(f'{label} roll {idx}')\n",
    "\n",
    "        x = df[X][start:end].to_numpy()\n",
    "        y = df[Y][start:end].to_numpy()\n",
    "        t = df[T][start:end].to_numpy()\n",
    "        s = df[SPEED][start:end].to_numpy()\n",
    "        speed.plot(t, s)\n",
    "\n",
    "        add_birds_eye_view(birds_eye, x, y, t)\n",
    "        add_crosshairs(speed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70d542-96cc-431c-89a0-4cdfe427ba49",
   "metadata": {},
   "source": [
    "# CSV Output\n",
    "We're ready to write the roll data out to disk. This duplicates some information from the raw data file, but it allows our analysis code to make a bunch of assumptions about the parsed data.\n",
    "\n",
    "By default this code will not overwrite an existing file. You must set `DANGEROUS = True` if you want to overwrite. \n",
    "\n",
    "Note the metadata that is included to provide clues to when and how these refrence points were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979fc55-cf45-4781-b685-51ec1e9bdf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the roll data out with header info so we know when and how it was processed\n",
    "output_dir = f'{DATA_DIR}/parsed'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "DANGEROUS = False\n",
    "mode = 'w' if DANGEROUS else 'x'\n",
    "for raw in data:\n",
    "    df = data[raw]\n",
    "    for roll_number, (start, end) in enumerate(rolls[raw]):\n",
    "        label = f'{raw}_{roll_number}'\n",
    "        with open(f'{output_dir}/{label}.csv', mode) as f:\n",
    "            newline = '\\n'\n",
    "            f.write(newline.join([\n",
    "                f'# Single Roll Data',\n",
    "                f'# version: alpha',\n",
    "                f'# label: {label}',\n",
    "                f'# sample_start: {start}',\n",
    "                f'# sample_end: {end}',\n",
    "                f'# generated: {datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")}',\n",
    "                f'# user: {os.getlogin()}',\n",
    "            ]))\n",
    "            f.write(newline)\n",
    "            df[start:end].to_csv(f, header=True, lineterminator='\\n', index=False)\n",
    "            print(f'Successfully wrote {label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065fc6bd-6c76-4c28-a2a0-f1d55ce789e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
